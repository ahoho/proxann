{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00dae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "from scipy.stats import kendalltau\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.proxann.prompter import Prompter\n",
    "from src.proxann.utils import process_responses, collect_fit_rank_data, compute_correlations_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c703f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src.proxann.prompter - INFO - Setting temperature to: 0\n",
      "src.proxann.prompter - INFO - Setting seed to: 1234\n",
      "src.proxann.prompter - INFO - Using OpenAI API with model: gpt-4o-2024-08-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config file ../config/config.yaml and section logger.\n",
      "Logs will be saved in data/logs\n",
      "Loaded config file ../config/config.yaml and section llm.\n"
     ]
    }
   ],
   "source": [
    "prompter = Prompter(model_type=\"gpt-4o-2024-08-06\", temperature=0, seed=1234, config_path=\"../config/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35fa81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "System message:\n",
    "\n",
    "Your input fields are:\n",
    "1. `CATEGORY` (str)\n",
    "2. `DOCUMENT` (str)\n",
    "\n",
    "Your output fields are:\n",
    "1. `reasoning` (str)\n",
    "2. `FIT` (int): An integer score from 1 to 5 indicating how well the DOCUMENT fits the given CATEGORY\n",
    "\n",
    "All interactions will be structured in the following way, with the appropriate values filled in.\n",
    "\n",
    "[[ ## CATEGORY ## ]]\n",
    "{CATEGORY}\n",
    "\n",
    "[[ ## DOCUMENT ## ]]\n",
    "{DOCUMENT}\n",
    "\n",
    "[[ ## reasoning ## ]]\n",
    "{reasoning}\n",
    "\n",
    "[[ ## FIT ## ]]\n",
    "{FIT}\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "\n",
    "In adhering to this structure, your objective is:\n",
    "        Determine whether the DOCUMENT fits with the given CATEGORY or not\n",
    "\n",
    "\n",
    "User message:\n",
    "\n",
    "[[ ## CATEGORY ## ]]\n",
    "Relevant religious buildings\n",
    "\n",
    "[[ ## DOCUMENT ## ]]\n",
    "Alchi Monastery = Alchi Monastery or Alchi Gompa is a Buddhist monastery, known more as a monastic complex ( chos- ' khor ) of temples in Alchi village in the Leh District, of the Indian state under the Ladakh Autonomous Hill Development Council of Jammu and Kashmir. The complex comprises four separate settlements in the Alchi village in the lower Ladakh region with monuments dated to different periods. Of these four hamlets, Alchi monastery is said to be the oldest and most famous. It is administered by the Likir Monastery. Alchi is also part of the three villages ( all in lower Ladakh region ) which constitute the ‘ Alchi group of monuments ’ ; the other two villages adjoining Alchi are the Mangyu and Sumda Chun.\n",
    "\n",
    "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## FIT ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
    "\n",
    "\n",
    "Assistant message:\n",
    "\n",
    "[[ ## reasoning ## ]]\n",
    "The document describes Alchi Monastery, which is a Buddhist monastery and a significant religious building in the Leh District of India. It provides details about its historical importance, architectural features, and its role within the local religious community. Since the category is \"Relevant religious buildings,\" and the document discusses a specific religious site, it fits well within this category.\n",
    "\n",
    "[[ ## FIT ## ]]\n",
    "5\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "\n",
    "\n",
    "User message:\n",
    "\n",
    "[[ ## CATEGORY ## ]]\n",
    "America professional basketball\n",
    "\n",
    "[[ ## DOCUMENT ## ]]\n",
    "2007 NBA betting scandal = The 2007 NBA betting scandal was a scandal involving the National Basketball Association ( NBA ) and accusations that an NBA referee used his knowledge of relationships between referees, coaches, players and owners to bet on professional basketball games. In July 2007, reports of an investigation by the Federal Bureau of Investigation ( FBI ) were made public, which alleged that during the 2005 – 06 and 2006 – 07 NBA seasons, referee Tim Donaghy bet on games in which he officiated. On August 15, 2007, Donaghy pleaded guilty to two federal charges related to the investigation, and a year later he was sentenced to 15 months in prison and three years of supervised release.\n",
    "\n",
    "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## FIT ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
    "\n",
    "\n",
    "Assistant message:\n",
    "\n",
    "[[ ## reasoning ## ]]\n",
    "The document discusses the 2007 NBA betting scandal, which directly involves the National Basketball Association (NBA) and its referees, players, and the integrity of professional basketball games. This topic is highly relevant to the category of \"America professional basketball\" as it pertains to a significant event in the history of the league and highlights issues related to gambling and officiating in professional basketball. Therefore, the document fits well within the category.\n",
    "\n",
    "[[ ## FIT ## ]]\n",
    "4\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "\n",
    "\n",
    "User message:\n",
    "\n",
    "[[ ## CATEGORY ## ]]\n",
    "Japanese and Korean Visual Novels and Manga Series\n",
    "\n",
    "[[ ## DOCUMENT ## ]]\n",
    "To Heart 2 = To Heart 2 ( トゥハート２, Tu Hāto 2 ), stylized as ToHeart2, is a Japanese romance visual novel developed by Leaf and published by Aquaplus. It was first released for the PlayStation 2 on December 28, 2004 as an all-ages title, and was followed by an adult version playable on Microsoft Windows and subsequent all-ages versions for the PlayStation Portable and PlayStation 3. This deviated from the release history of the game 's predecessor, To Heart, which was originally released with adult content prior to receiving versions with such content removed.\n",
    "\n",
    "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## FIT ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ed33537",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Please act as an impartial judge and assign an integer score from 1 to 5 indicating how well the DOCUMENT fits the given CATEGORY. Do not provide any reasoning or explanation\n",
    "\n",
    "[[ ## CATEGORY ## ]]\n",
    "Japanese and Korean Visual Novels and Manga Series\n",
    "\n",
    "[[ ## DOCUMENT ## ]]\n",
    "To Heart 2 = To Heart 2 ( トゥハート２, Tu Hāto 2 ), stylized as ToHeart2, is a Japanese romance visual novel developed by Leaf and published by Aquaplus. It was first released for the PlayStation 2 on December 28, 2004 as an all-ages title, and was followed by an adult version playable on Microsoft Windows and subsequent all-ages versions for the PlayStation Portable and PlayStation 3. This deviated from the release history of the game 's predecessor, To Heart, which was originally released with adult content prior to receiving versions with such content removed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba941504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache key: e918d19710229453583f8ed452a07cad\n"
     ]
    }
   ],
   "source": [
    "response_q2, logprobs = prompter.prompt(None, template, use_context=False, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17617c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TopLogprob(token='5', bytes=[53], logprob=-0.014185127802193165),\n",
       " TopLogprob(token='4', bytes=[52], logprob=-4.264184951782227),\n",
       " TopLogprob(token='3', bytes=[51], logprob=-10.764184951782227),\n",
       " TopLogprob(token='1', bytes=[49], logprob=-14.889184951782227),\n",
       " TopLogprob(token='2', bytes=[50], logprob=-15.889184951782227),\n",
       " TopLogprob(token='Score', bytes=[83, 99, 111, 114, 101], logprob=-16.764184951782227),\n",
       " TopLogprob(token='The', bytes=[84, 104, 101], logprob=-17.889184951782227),\n",
       " TopLogprob(token=' ', bytes=[32], logprob=-18.514184951782227),\n",
       " TopLogprob(token='[[', bytes=[91, 91], logprob=-19.139184951782227),\n",
       " TopLogprob(token='6', bytes=[54], logprob=-20.014184951782227),\n",
       " TopLogprob(token='Category', bytes=[67, 97, 116, 101, 103, 111, 114, 121], logprob=-20.389184951782227),\n",
       " TopLogprob(token='\\n', bytes=[10], logprob=-20.514184951782227),\n",
       " TopLogprob(token='<|end|>', bytes=None, logprob=-20.514184951782227),\n",
       " TopLogprob(token='Five', bytes=[70, 105, 118, 101], logprob=-20.764184951782227),\n",
       " TopLogprob(token='I', bytes=[73], logprob=-21.764184951782227),\n",
       " TopLogprob(token='Assign', bytes=[65, 115, 115, 105, 103, 110], logprob=-22.201684951782227),\n",
       " TopLogprob(token='５', bytes=[239, 188, 149], logprob=-22.451684951782227),\n",
       " TopLogprob(token='CATEGORY', bytes=[67, 65, 84, 69, 71, 79, 82, 89], logprob=-22.576684951782227),\n",
       " TopLogprob(token='To', bytes=[84, 111], logprob=-22.576684951782227),\n",
       " TopLogprob(token='Rating', bytes=[82, 97, 116, 105, 110, 103], logprob=-22.701684951782227)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[0].top_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316a914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Token: Score could not be converted to int\n",
      "Token: The could not be converted to int\n",
      "Token:   could not be converted to int\n",
      "Token: [[ could not be converted to int\n",
      "Token: Category could not be converted to int\n",
      "Token: \n",
      " could not be converted to int\n",
      "Token: <|end|> could not be converted to int\n",
      "Token: Five could not be converted to int\n",
      "Token: I could not be converted to int\n",
      "Token: Assign could not be converted to int\n",
      "Token: CATEGORY could not be converted to int\n",
      "Token: To could not be converted to int\n",
      "Token: Rating could not be converted to int\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.985892358591917"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "tokens_probs = []\n",
    "word_to_number = {\n",
    "    \"uno\": 1,\n",
    "    \"dos\": 2,   \n",
    "    \"tres\": 3,\n",
    "    \"cuatro\": 4,\n",
    "    \"cinco\": 5\n",
    "}\n",
    "\n",
    "print(len(logprobs[0].top_logprobs))\n",
    "for top_logprobs in logprobs[0].top_logprobs:\n",
    "    raw_token = top_logprobs.token\n",
    "    try:\n",
    "        token_str = str(raw_token).lower()\n",
    "        token = word_to_number.get(token_str, int(raw_token))\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"Token: {raw_token} could not be converted to int\")\n",
    "        continue\n",
    "\n",
    "    if token in {1, 2, 3, 4, 5}:  # set is faster for membership tests\n",
    "        prob = math.exp(top_logprobs.logprob)\n",
    "        tokens_probs.append((token, prob))\n",
    "\n",
    "# final score\n",
    "score = sum(token * prob for token, prob in tokens_probs)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb288918",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7a46031",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jsons = [\n",
    "    \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/data_used_in_paper/json_out/config_bills_part1.json\",\n",
    "    \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/data_used_in_paper/json_out/config_bills_part2.json\",\n",
    "    \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/data_used_in_paper/json_out/config_pilot_wiki_part2.json\",\n",
    "    \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/data_used_in_paper/json_out/config_pilot_wiki.json\"\n",
    "]\n",
    "response_csvs = [\n",
    "    \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/data_used_in_paper/qualtrics/Cluster+Evaluation+-+Sort+and+Rank_December+12,+2024_05.19.csv\",\n",
    "    \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/data_used_in_paper/qualtrics/Cluster+Evaluation+-+Sort+and+Rank+-+Bills_December+14,+2024_13.20.csv\"\n",
    "]\n",
    "\n",
    "llm_data_paths = {\n",
    "    \"wiki\": {\n",
    "        \"gpt4o-mini-bin\": \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/data_used_in_paper/llm_results/wiki/q1_then_q3_dspy,q1_then_q2_dspy_gpt-4o-mini-2024-07-18_20241213_102655\",\n",
    "        \n",
    "        \"gpt4o-mini-non-bin\": \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/paper_wang/wiki/q1_then_q2_dspy,q1_then_q3_dspy_gpt-4o-mini-2024-07-18_20250415_163508\",\n",
    "       \n",
    "        \"gpt4o-non-bin\": \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/paper_wang/wiki/q1_then_q2_dspy,q1_then_q3_dspy_gpt-4o-2024-08-06_20250415_164926\",\n",
    "    }\n",
    "}\n",
    "\n",
    "cohr_path = [\"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/cohrs/all_cohrs_bills.csv\", \"/export/usuarios_ml4ds/lbartolome/Repos/umd/theta-evaluation/data/cohrs/all_cohrs_wiki.csv\"]\n",
    "\n",
    "start_date = \"2024-12-06 09:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaa0ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total responses: 142\n",
      "Total responses: 142\n",
      "Removed: 25\n",
      "Total responses: 121\n",
      "Total responses: 121\n",
      "Removed: 20\n"
     ]
    }
   ],
   "source": [
    "responses = {}\n",
    "for csv in response_csvs:\n",
    "    for topic_id, topic_responses in process_responses(csv, data_jsons, start_date=start_date, path_save=None, removal_condition=\"loose\").items():\n",
    "        if topic_responses:\n",
    "            responses[topic_id] = topic_responses\n",
    "\n",
    "_, _, _, corr_data = collect_fit_rank_data(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0c2cdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wiki dataset\n",
      "TAU of tau\n",
      "                         fit_wiki rank_wiki\n",
      "npmi                     0.029091 -0.122022\n",
      "cv                      -0.036364 -0.203369\n",
      "fit_gpt4o-mini-bin       0.455181  0.182271\n",
      "rank_gpt4o-mini-bin      0.451972  0.447997\n",
      "fit_gpt4o-mini-non-bin   0.153316  0.106467\n",
      "rank_gpt4o-mini-non-bin  0.033916  0.114956\n",
      "fit_gpt4o-non-bin        0.311568  0.423692\n",
      "rank_gpt4o-non-bin       0.203891  0.307148\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read coherence metrics\n",
    "cohrs = pd.concat([pd.read_csv(cohr_path[0]), pd.read_csv(cohr_path[1])]).to_dict(orient=\"records\")\n",
    "\n",
    "corr_ids = [x[\"id\"] for x in corr_data]\n",
    "corr_metric = \"agree\" #\"tau\"\n",
    "agg = \"mean\"\n",
    "\n",
    "for corr_metric in [\"tau\"]:#, \"agree\"\n",
    "\n",
    "    # Obtener las claves internas del primer nivel del diccionario\n",
    "    row_names = [\"npmi\", \"cv\"] + \\\n",
    "    [f\"{metric}_{llm}\" for llm in list(llm_data_paths[list(llm_data_paths.keys())[0]].keys()) for metric in [\"fit\", \"rank\"]]\n",
    "\n",
    "    column_names = [f\"{metric}_{dataset}\" for dataset in [\"wiki\"] for metric in [\"fit\", \"rank\"]]\n",
    "\n",
    "    results_df = pd.DataFrame(index=row_names, columns=column_names)\n",
    "\n",
    "    corrs_mode_1 = defaultdict(dict)\n",
    "    # Fill the DataFrame with calculated values\n",
    "    for dataset in [\"wiki\"]:\n",
    "        print(f\"Processing {dataset} dataset\")\n",
    "        llm_fits, llm_ranks = {}, {}\n",
    "        for llm, path in llm_data_paths[dataset].items():\n",
    "            fits = pd.read_json(f\"{path}/llm_results_q2.json\").to_dict(orient=\"records\")\n",
    "            ranks = pd.read_json(f\"{path}/llm_results_q3.json\").to_dict(orient=\"records\")\n",
    "            for item in fits:\n",
    "                item[\"annotators\"] = [llm]\n",
    "            for item in ranks:\n",
    "                item[\"annotators\"] = [llm]\n",
    "            llm_fits[llm] = fits\n",
    "            llm_ranks[llm] = ranks\n",
    "        \n",
    "        for llm in llm_data_paths[dataset]:  # Iterate through each LLM\n",
    "            \n",
    "            dtset_corr_ids = [x for x in corr_ids if dataset in x]\n",
    "        \n",
    "            filtered_ranks = [x for x in llm_ranks[llm] if x[\"id\"] in dtset_corr_ids]\n",
    "            filtered_fits = [x for x in llm_fits[llm] if x[\"id\"] in dtset_corr_ids]\n",
    "            filtered_cohrs = [x for x in cohrs if x[\"id\"] in dtset_corr_ids] \n",
    "            filtered_corr_data = [x for x in corr_data if x[\"id\"] in dtset_corr_ids]\n",
    "            \n",
    "            # ensure that the lists are sorted by id        \n",
    "            filtered_ranks = sorted(filtered_ranks, key=lambda x: x[\"id\"])\n",
    "            filtered_fits = sorted(filtered_fits, key=lambda x: x[\"id\"])\n",
    "            filtered_cohrs = sorted(filtered_cohrs, key=lambda x: x[\"id\"])\n",
    "            filtered_corr_data = sorted(filtered_corr_data, key=lambda x: x[\"id\"])\n",
    "            \n",
    "            ids_fits = [x[\"id\"] for x in filtered_fits]\n",
    "            ids_ranks = [x[\"id\"] for x in filtered_ranks]\n",
    "            ids_corr = [x[\"id\"] for x in filtered_corr_data]\n",
    "                    \n",
    "            # check equality of ids\n",
    "            assert ids_fits == ids_ranks == ids_corr\n",
    "                    \n",
    "            npmi_cohrs = [x[\"npmi\"] for x in filtered_cohrs]\n",
    "            cv_cohrs = [x[\"cv\"] for x in filtered_cohrs]\n",
    "\n",
    "            #import pdb; pdb.set_trace()\n",
    "            corrs_mode1_llm = compute_correlations_one(filtered_corr_data, filtered_ranks, filtered_fits, aggregation_method=agg)\n",
    "            \n",
    "            corrs_mode_1[dataset][llm] = corrs_mode1_llm\n",
    "\n",
    "            for user_metric in [\"fit\", \"rank\"]:#, \"rank\"]\n",
    "                user_tm_metric = corrs_mode1_llm[f\"{user_metric}_{corr_metric}\"]\n",
    "\n",
    "                # Correlate user_tm_metric with npmi and cv\n",
    "                npmi_user_metric = kendalltau(npmi_cohrs, user_tm_metric, nan_policy=\"omit\").statistic\n",
    "                cv_user_metric = kendalltau(cv_cohrs, user_tm_metric, nan_policy=\"omit\").statistic\n",
    "\n",
    "                # Store the npmi and cv correlations in the DataFrame\n",
    "                results_df.loc[\"npmi\", f\"{user_metric}_{dataset}\"] = npmi_user_metric\n",
    "                results_df.loc[\"cv\", f\"{user_metric}_{dataset}\"] = cv_user_metric\n",
    "\n",
    "                for llm_metric in [\"fit\", \"rank\"]: #, \"rank\"\n",
    "                    llm_tm_metric = corrs_mode1_llm[f\"{llm_metric}_{corr_metric}_tm_{llm}\"]\n",
    "                    \n",
    "                    # Correlate user_tm_metric with llm_tm_metric\n",
    "                    tau_topic_rank = kendalltau(llm_tm_metric, user_tm_metric, nan_policy=\"omit\").statistic\n",
    "\n",
    "                    # Store the topic ranking correlation in the DataFrame\n",
    "                    results_df.loc[f\"{llm_metric}_{llm}\", f\"{user_metric}_{dataset}\"] = tau_topic_rank\n",
    "\n",
    "    print(f\"TAU of {corr_metric}\")\n",
    "    print(results_df)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c3e23fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank_rho                           0.50885\n",
      "rank_tau                          0.422711\n",
      "rank_ndcg                         0.843065\n",
      "rank_rho_users_gpt4o-mini-bin     0.654334\n",
      "rank_rho_tm_gpt4o-mini-bin        0.469563\n",
      "rank_tau_users_gpt4o-mini-bin     0.544803\n",
      "rank_tau_tm_gpt4o-mini-bin        0.355845\n",
      "rank_ndcg_users_gpt4o-mini-bin    0.904824\n",
      "rank_ndcg_tm_gpt4o-mini-bin        0.73166\n",
      "dtype: object\n",
      "\n",
      "\n",
      "rank_rho                               0.50885\n",
      "rank_tau                              0.422711\n",
      "rank_ndcg                             0.843065\n",
      "rank_rho_users_gpt4o-mini-non-bin     0.527159\n",
      "rank_rho_tm_gpt4o-mini-non-bin        0.529075\n",
      "rank_tau_users_gpt4o-mini-non-bin     0.435986\n",
      "rank_tau_tm_gpt4o-mini-non-bin        0.408998\n",
      "rank_ndcg_users_gpt4o-mini-non-bin    0.864052\n",
      "rank_ndcg_tm_gpt4o-mini-non-bin       0.765549\n",
      "dtype: object\n",
      "\n",
      "\n",
      "rank_rho                          0.50885\n",
      "rank_tau                         0.422711\n",
      "rank_ndcg                        0.843065\n",
      "rank_rho_users_gpt4o-non-bin     0.668343\n",
      "rank_rho_tm_gpt4o-non-bin        0.528075\n",
      "rank_tau_users_gpt4o-non-bin     0.588642\n",
      "rank_tau_tm_gpt4o-non-bin         0.41642\n",
      "rank_ndcg_users_gpt4o-non-bin    0.893238\n",
      "rank_ndcg_tm_gpt4o-non-bin       0.752312\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "columns_show = [col for col in corrs_mode_1[\"wiki\"][\"gpt4o-mini-bin\"].columns if \"rank\" in col]\n",
    "print(corrs_mode_1[\"wiki\"][\"gpt4o-mini-bin\"].aggregate(lambda x: x.mean() if x.dtype == \"float64\" else x.mode()[0], axis=0)[columns_show])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "columns_show = [col for col in corrs_mode_1[\"wiki\"][\"gpt4o-mini-non-bin\"].columns if \"rank\" in col]\n",
    "print(corrs_mode_1[\"wiki\"][\"gpt4o-mini-non-bin\"].aggregate(lambda x: x.mean() if x.dtype == \"float64\" else x.mode()[0], axis=0)[columns_show])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "columns_show = [col for col in corrs_mode_1[\"wiki\"][\"gpt4o-non-bin\"].columns if \"rank\" in col]\n",
    "print(corrs_mode_1[\"wiki\"][\"gpt4o-non-bin\"].aggregate(lambda x: x.mean() if x.dtype == \"float64\" else x.mode()[0], axis=0)[columns_show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a263f5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_rho                            0.51491\n",
      "fit_tau                           0.427663\n",
      "fit_agree                         0.761905\n",
      "fit_ndcg                          0.888187\n",
      "fit_tau_users_gpt4o-mini-bin      0.540727\n",
      "fit_tau_tm_gpt4o-mini-bin         0.400193\n",
      "fit_agree_users_gpt4o-mini-bin    0.422619\n",
      "fit_agree_tm_gpt4o-mini-bin       0.339286\n",
      "dtype: object\n",
      "\n",
      "\n",
      "fit_rho                                0.51491\n",
      "fit_tau                               0.427663\n",
      "fit_agree                             0.761905\n",
      "fit_ndcg                              0.888187\n",
      "fit_tau_users_gpt4o-mini-non-bin       0.51821\n",
      "fit_tau_tm_gpt4o-mini-non-bin          0.37233\n",
      "fit_agree_users_gpt4o-mini-non-bin    0.738095\n",
      "fit_agree_tm_gpt4o-mini-non-bin       0.690476\n",
      "dtype: object\n",
      "\n",
      "\n",
      "fit_rho                           0.51491\n",
      "fit_tau                          0.427663\n",
      "fit_agree                        0.761905\n",
      "fit_ndcg                         0.888187\n",
      "fit_tau_users_gpt4o-non-bin      0.554961\n",
      "fit_tau_tm_gpt4o-non-bin         0.404736\n",
      "fit_agree_users_gpt4o-non-bin    0.815476\n",
      "fit_agree_tm_gpt4o-non-bin       0.720238\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "columns_show = [col for col in corrs_mode_1[\"wiki\"][\"gpt4o-mini-bin\"].columns if \"fit\" in col]\n",
    "print(corrs_mode_1[\"wiki\"][\"gpt4o-mini-bin\"].aggregate(lambda x: x.mean() if x.dtype == \"float64\" else x.mode()[0], axis=0)[columns_show])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "columns_show = [col for col in corrs_mode_1[\"wiki\"][\"gpt4o-mini-non-bin\"].columns if \"fit\" in col]\n",
    "print(corrs_mode_1[\"wiki\"][\"gpt4o-mini-non-bin\"].aggregate(lambda x: x.mean() if x.dtype == \"float64\" else x.mode()[0], axis=0)[columns_show])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "columns_show = [col for col in corrs_mode_1[\"wiki\"][\"gpt4o-non-bin\"].columns if \"fit\" in col]\n",
    "print(corrs_mode_1[\"wiki\"][\"gpt4o-non-bin\"].aggregate(lambda x: x.mean() if x.dtype == \"float64\" else x.mode()[0], axis=0)[columns_show])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
